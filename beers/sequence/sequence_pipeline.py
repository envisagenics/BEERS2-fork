import importlib
import pathlib
import os
import time
import numpy as np
import resource
import json
import re
from beers_utils.constants import CONSTANTS
from beers.cluster_packet import ClusterPacket
from beers_utils.general_utils import GeneralUtils
from beers.auditor import Auditor


class SequencePipeline:
    """
    The class runs all the steps in the sequence pipeline as described and wired together in the configuration
    file.  The point of entry into this class is the static method main().
    """

    stage_name = "sequence_pipeline"
    package = "beers.sequence"

    def __init__(self, configuration, global_config, output_directory_path, directory_structure, cluster_packet):
        """
        Many initialization steps here include identifying the log and data directories and subdirectories so
        that data and log files generated are placed in the correct locations.  Note that the directory structure
        has already been created by the controller.  The steps described in the configuration dictionary are
        instantiated and those instantialed steps are added to a list to further use.
        :param configuration: dictionary of the configuration data relevant to this pipeline stage.
        :param global_config:  dictionary of the full configuration data
        :param output_directory_path: top level directory for data and logs generated by this pipeline stage
        :param directory_structure: instructions for navigating the subdirectories under the output directory
        :param cluster_packet: the cluster packet to run through this pipeline stage
        """
        self.cluster_packet = cluster_packet
        log_directory_path = os.path.join(output_directory_path, CONSTANTS.LOG_DIRECTORY_NAME)
        data_directory_path = os.path.join(output_directory_path, CONSTANTS.DATA_DIRECTORY_NAME)
        subdirectory_list = \
            GeneralUtils.get_output_subdirectories(self.cluster_packet.cluster_packet_id, directory_structure)
        data_subdirectory_path = os.path.join(data_directory_path, *subdirectory_list)
        self.log_file_path = os.path.join(log_directory_path,
                                          f"{SequencePipeline.stage_name}_"
                                          f"cluster_pkt{self.cluster_packet.cluster_packet_id}.log")
        self.global_config = global_config

        # Load and instantiate all steps listed in configuration
        self.steps = []
        for step in configuration['steps']:
            module_name, step_name = step["step_name"].rsplit(".")
            step_log_filename = f"{step_name}_cluster_pkt{self.cluster_packet.cluster_packet_id}.log"
            step_log_file_path = os.path.join(log_directory_path, step_name, *subdirectory_list, step_log_filename)
            parameters = step["parameters"]
            module = importlib.import_module(f'.{module_name}', package=SequencePipeline.package)
            step_class = getattr(module, step_name)
            self.steps.append(step_class(step_log_file_path, parameters, self.global_config))

        results_filename = f"{SequencePipeline.stage_name}_" \
                           f"result_cluster_pkt{self.cluster_packet.cluster_packet_id}.gzip"
        self.results_file_path = os.path.join(data_subdirectory_path, results_filename)

    @staticmethod
    def validate(configuration, global_configuration):
        """
        Static method to run each step validate process to identify errant parameters.  If any errors are found,
        a validation exception is raised.
        """
        steps = []
        # Find the step classes in the configuration
        for step in configuration['steps']:
            module_name, step_name = step["step_name"].rsplit(".")
            parameters = step["parameters"]
            module = importlib.import_module(f'.{module_name}', package=SequencePipeline.package)
            step_class = getattr(module, step_name)
            steps.append(step_class(None, parameters, global_configuration))
        # Validate configuration of each step
        if not all([step.validate() for step in steps]):
            raise BeersSequenceValidationException("Validation error in step: see stderr for details.")

    def execute(self):
        """
        Opens the pipeline log for writing and serially runs the execute method of each step object found in the
        step list generated when this pipeline stage was initialized.  The final product (a cluster packet
        modified with additional information) is serialized into a data file.
        :return:
        """
        print(f"Execution of the {SequencePipeline.stage_name} Started...")
        with open(self.log_file_path, 'w') as log_file:
            pipeline_start = time.time()
            cluster_packet = self.cluster_packet
            for step in self.steps:
                cluster_packet = step.execute(cluster_packet)

                # Saves the state of the random number generator after completion of each step in the event that
                # we may need to do to partial repeat of the sequence pipeline stage (although exactly how
                # to implement such a partial repeat hasn't been given serious consideration as yet).
                random_state = np.random.get_state()
                log_file.write(f"# random state following {step.__class__.__name__} is {random_state}\n")
                print(f"{step.__class__.name} complete - process RAM currently at"
                      f" {resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1E6} GB")

            pipeline_elapsed_time = time.time() - pipeline_start
            print(f"Finished sequence pipeline in {pipeline_elapsed_time:.1f} seconds")

        # Write final sample to a gzip file for inspection
        cluster_packet.serialize(self.results_file_path)
        print(f"Output final sample to {self.results_file_path}")

    @staticmethod
    def main(seed, configuration, configuration_file_path, output_directory_path,
             directory_structure, cluster_packet_path):
        """
        This method would be called by a command line script in the bin directory.  It sets a random seed, loads a
        directory containing the relevant parts of the user's configuration file, unmarshalls a cluster packet from
        the provided cluster packet filename, initializes and validates the sequence pipeline stage and then
        executes it for the cluster packet.  Since the controller cannot conclude until all sequence pipelines are
        run, the last action taken by the sequence pipeline is to note its completion to the auditor, which records
        the cluster id in an audit file.  This happens regardless of the outcome of this pipeline stage.
        :param seed: value to use as the seed for the random number generator
        :param configuration: the json string containing the configration data specific to the library prep pipeline
        :param configuration_file_path: path to the full configuration data
        :param output_directory_path: top level output directory path for this pipeline stage
        :param directory_structure: instructions for creating the scaffolding needed to house the pipeline data and logs
        :param cluster_packet_path: the file from which to unmarshall the cluster packet
        """
        # Normally the cluster_packet_id should be derived from the serialized cluster_packet in the file.  But if
        # the file cannot be found, we still need an id to report back to the auditor if at all possible.  So we
        # extract it from the file name just in case.
        cluster_packet = None
        cluster_packet_filename = str(pathlib.Path(cluster_packet_path).name)
        cluster_packet_id_pattern = re.compile(r'^.*cluster_packet.*_pkt(\d+)\..*$')
        cluster_packet_id_match = re.match(cluster_packet_id_pattern, cluster_packet_path)
        cluster_packet_id = None if not cluster_packet_id_match else cluster_packet_id_match.group(1)
        try:
            np.random.seed(int(seed))
            configuration = json.loads(configuration)
            with open(configuration_file_path) as config_file:
                global_config = json.load(config_file)
            cluster_packet = ClusterPacket.get_serialized_cluster_packet(cluster_packet_path)
            sequence_pipeline = SequencePipeline(
                    configuration,
                    global_config,
                    output_directory_path,
                    directory_structure,
                    cluster_packet
            )
            sequence_pipeline.execute()
        finally:
            # Using the file name to recover the cluster packet id only if the cluster_packet was never created.
            # They should be the same.
            cluster_packet_id = cluster_packet_id if not cluster_packet else cluster_packet,cluster_packet_id
            Auditor.note_packet_completed(cluster_packet_id, output_directory_path)


class BeersSequenceValidationException(Exception):
    pass
