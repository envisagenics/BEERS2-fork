import importlib
import pathlib
import time
import re
import os
import resource
import json
import math

import numpy as np

from beers_utils.sample import Sample
from beers_utils.constants import CONSTANTS
from beers_utils.molecule import Molecule
from beers_utils.molecule_packet import MoleculePacket
from beers_utils.general_utils import GeneralUtils

from camparee.molecule_maker import MoleculeMakerStep
from camparee.camparee_constants import CAMPAREE_CONSTANTS


class LibraryPrepPipeline:
    """
    The class runs all the steps in the library_prep pipeline as described ans wired together in the configuration
    file.  The point of entry into this class is the static method main().  In HPC scenarios, this object's main is
    invoked on each node included in the compute, with a different molecule packet delivered to each node.
    """

    stage_name = "library_prep_pipeline"
    pipeline_log_subdirectory_name = "Pipeline"
    package = "beers.library_prep"

    def __init__(self, configuration, global_config, output_directory_path, directory_structure, molecule_packet):
        """
        Many initialization steps here include identifying the log and data directories and subdirectories so
        that data and log files generated are placed in the correct locations.  Note that the directory structure
        has already been created by the controller.  The steps described in the configuration dictionary are
        instantiated and those instantiated steps are added to a list for later invocation.
        :param configuration:  dictionary of the configuration data relevant to this pipeline stage.
        :param gloabl_config: dictionary of full config data
        :param output_directory_path: top level directory for data and logs generated by this pipeline stage
        :param directory_structure: instructions for navigating the subdirectories under the output directory
        :param molecule_packet: the molecule packet to run through this pipeline stage
        """
        self.molecule_packet = molecule_packet
        self.log_directory_path = os.path.join(output_directory_path, CONSTANTS.LOG_DIRECTORY_NAME)
        data_directory_path = os.path.join(output_directory_path, CONSTANTS.DATA_DIRECTORY_NAME)
        subdirectory_list = \
            GeneralUtils.get_output_subdirectories(self.molecule_packet.molecule_packet_id, directory_structure)
        data_subdirectory_path = os.path.join(data_directory_path, *subdirectory_list)
        self.original_ids = set(str(m.molecule_id) for m in self.molecule_packet.molecules)
        self.print_summary(self.molecule_packet.molecules)
        self.log_file_path = os.path.join(self.log_directory_path,
                                          LibraryPrepPipeline.pipeline_log_subdirectory_name,
                                          *subdirectory_list,
                                          f"{LibraryPrepPipeline.stage_name}_"
                                          f"molecule_pkt{self.molecule_packet.molecule_packet_id}.log")
        self.global_config = global_config
        self.steps = []
        for step in configuration['steps']:
            module_name, step_name = step["step_name"].rsplit(".")
            step_log_filename = f"{step_name}_molecule_pkt{self.molecule_packet.molecule_packet_id}.log"
            step_log_file_path = os.path.join(self.log_directory_path, step_name, *subdirectory_list, step_log_filename)
            parameters = step["parameters"]
            module = importlib.import_module(f'.{module_name}', package=LibraryPrepPipeline.package)
            step_class = getattr(module, step_name)
            self.steps.append(step_class(step_log_file_path, parameters, global_config))
        results_filename = f"{LibraryPrepPipeline.stage_name}_" \
                           f"result_molecule_pkt{self.molecule_packet.molecule_packet_id}.txt"
        self.results_file_path = os.path.join(data_subdirectory_path, results_filename)

    @staticmethod
    def validate(configuration, global_config):
        """
        Static method to run each step validate process to identify errant parameters.  If any errors are found,
        a validation exception is raised.
        """
        #if not all([molecule.validate() for molecule in self.molecule_packet.molecules]):
        #    raise BeersLibraryPrepValidationException("Validation error in molecule packet: see stderr for details.")
        steps = []
        for step in configuration['steps']:
            module_name, step_name = step["step_name"].rsplit(".")
            parameters = step["parameters"]
            module = importlib.import_module(f'.{module_name}', package=LibraryPrepPipeline.package)
            step_class = getattr(module, step_name)
            steps.append(step_class(None, parameters, global_config))
        if not all([step.validate() for step in steps]):
            raise BeersLibraryPrepValidationException("Validation error in step: see stderr for details.")

    def execute(self):
        """
        Opens the pipeline log for writing and serially runs the execute method of each step object found in the
        step list generated when this pipeline stage was initialized.  The final product (a modified molecule
        packet) is serialized into a data file.
        """
        # TODO what about gzipping?
        with open(self.log_file_path, 'w') as log_file:
            self.log_sample(log_file)
            pipeline_start = time.time()
            molecule_packet = self.molecule_packet
            for step in self.steps:
                step_name = step.__class__.name if hasattr(step.__class__, 'name') else step.__class__.__name__
                step_start = time.time()
                molecule_packet = step.execute(molecule_packet)
                elapsed_time = time.time() - step_start

                self.print_summary(molecule_packet.molecules, elapsed_time)

                # Saves the state of the random number generator after completion of each step in the event that
                # we may need to do to partial repeat of the library_prep pipeline stage (although exactly how
                # to implement such a partial repeat hasn't been given serious consideration as yet).
                random_state = np.random.get_state()
                log_file.write(f"# random state following {step_name} is {random_state}\n")
                print(f"{step_name} complete - process RAM currently at"
                      f" {resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1E6} GB")

            pipeline_elapsed_time = time.time() - pipeline_start
            print(f"Finished {LibraryPrepPipeline.stage_name} in {pipeline_elapsed_time:.1f} seconds")

        # Write final sample to a gzip file for inspection
        molecule_packet.serialize(self.results_file_path)
        print(f"Output final sample to {self.results_file_path}")

    def log_sample(self, log_file):
        """
        Logs the molecules the pipeline stage begins with.  We need to
        consider gzipping.
        :param log_file: The handle to the log file.
        """
        log_file.write(Molecule.header)
        for molecule in self.molecule_packet.molecules:
            log_file.write(molecule.log_entry())

    def print_summary(self, sample, elapsed_time=None):
        """
        Output a summary of the sample (number of molecules, time taken, etc.)
        :param sample:
        :param elapsed_time:
        """
        if elapsed_time is not None:
            print(f"Step took {elapsed_time:.3} seconds")

        print(f"Sample has {len(sample)} molecules")
        parent_ids = set(str(m.molecule_id).split(".")[0] for m in sample)
        #TODO: this does not seem to be calculated correctly: always gives 0
        percent_original_represented = len(self.original_ids.intersection(parent_ids))/len(self.original_ids)
        print(f"Percent of the original ids that are still represented: {percent_original_represented:0.2%}")

        size_bin_cutoffs = [100, 500, 1000]
        size_counts = [0]*(len(size_bin_cutoffs)+1)
        for molecule in sample:
            size_counts[np.searchsorted(size_bin_cutoffs, len(molecule))] += 1
        print(f"Counts of molecules in size ranges:")
        for i in range(len(size_bin_cutoffs)):
            print(f" <={size_bin_cutoffs[i]}: {size_counts[i]}")
        print(f">{size_bin_cutoffs[-1]}: {size_counts[-1]}")

    @staticmethod
    def main(seed, configuration, configuration_file_path, output_directory_path,
             directory_structure, molecule_packet_filename, packet_id,
             distribution_directory = None, molecules_per_packet_from_distribution = 10000,
             sample_id = None,
             ):
        """
        This method would be called by a command line script in the bin directory.  It sets a random seed, loads a
        directory containing the relevant parts of the user's configuration file, unmarshalls a molecule packet from
        the provided molecule packet filename, initializes and validates the library prep pipeline stage and then
        executes it for the molecule packet.
        :param seed: value to use as the seed for the random number generator
        :param configuration: the json string containing the configration data specific to the library prep pipeline
        :param configuration_file_path: path to the full config file
        :param output_directory_path: top level output directory path for this pipeline stage
        :param directory_structure: instructions for creating the scaffolding needed to house the pipeline data and logs
        :param molecule_packet_filename: the file from which to unmarshall the molecule packet
        :param packet_id: id number to assign the packet
        :param distribution_directory: directory of CAMPAREE output distribution datas from which to generate molecules
            (default None, must supply molecule_packet_filename instead)
        :param molecules_per_packet_from_distribution: packet size to generate if using distributions
        :param sample_id: id number of the sample
        """
        np.random.seed(int(seed))
        configuration = json.loads(configuration)
        with open(configuration_file_path) as config_file:
            global_configuration = json.load(config_file)
        molecule_maker_parameters = global_configuration['molecule_maker_parameters']
        packet_id = None if packet_id == 'None' else int(packet_id)
        if molecule_packet_filename:
            molecule_packet = MoleculePacket.from_CAMPAREE_molecule_file(molecule_packet_filename, packet_id)
        elif distribution_directory:
            mm_log_path = output_directory_path # TODO should this go somewhere else?
            distribution_dir = pathlib.Path(distribution_directory)
            sample = Sample(
                sample_id = sample_id,
                sample_name = sample_id,
                adapter_sequences = [],
                fastq_file_paths = [],
                pooled = False,
            )
            molecule_maker = MoleculeMakerStep(
                    log_directory_path = mm_log_path,
                    parameters = molecule_maker_parameters,
            )
            molecule_packets = list(molecule_maker.execute(
                    sample = sample,
                    sample_data_directory = distribution_dir,
                    output_type =  "generator",
                    output_molecule_count = molecules_per_packet_from_distribution, # we only generate one packet
                    seed = seed,
                    molecules_per_packet = molecules_per_packet_from_distribution,
            ))
            molecule_packet = molecule_packets[0]
            molecule_packet.molecule_packet_id = packet_id
        else:
            raise BeersLibraryPrepValidationException("Neither molecule packet filename nor distribution directory provided")
        library_prep_pipeline = LibraryPrepPipeline(configuration, global_configuration, output_directory_path, directory_structure,
                                                    molecule_packet)
        library_prep_pipeline.execute()


class BeersLibraryPrepValidationException(Exception):
    pass
